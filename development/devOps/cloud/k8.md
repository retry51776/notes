# kubernetes
> start from Google Borg

> Infracture as code

> https://artifacthub.io/

> all k8 resources types: https://kubernetes.io/docs/reference/kubectl/overview/#resource-types


`kubectl [create|edit|get|delete]`
## K8 Objects
- job
- cronjob `https://crontab.guru/`
- deployment
- pods
- service
- ingress
- event
- secrets
- configMap

## K8 CMD
```
kubectl create job --from=cronjob/mycronjob name-of-one-off-job
kubectl run XXXX --images=XXXX --port=80  
kubectl exec -it pod-name sh
kubectl rollout restart deployment xyz
kubectl rollout undo deployment myapp
kubectl rollout history deploy myapp --revision=2

// Almost never do this  
kubectl expose deployment XXXX --type="LoadBalancer" service "XXXX" exposed  
  
ps auxww // Show all process
```

## Tech terms
> containerD and cri-o are container runtime

> open container initiative

> ingress is K8 build in route control traefik similar to ingress, but more features nginx

> application layer encryption for secrets

> service mesh

> Cloud Native Computing Foundation (CNCF)

  
## K8 components:
- Mater Node
  - Scheduler
    - Trigger Cron Jobs
  - Control Mgr
    - Compare Active State vs Desired State
  - etcd
    - key/value DB
  - API service
    - Supports cmds
- Worker Node
  - Container Run Time
    - Pods //smallest k8 unit
  - Kubproxy
    - route & selector
  - Kubelet
    - communicate with API-service

## Node Components
- kubelet
  1. Scheduled: assign pod to node
  2. Pull: pull image
  3. Start: start pod
- kube-proxy
  1. manage iptables rules by Service def
  2. Internal DNS & load balancer
- container runtime
  - CRI-O
  - containerd (cri-dockerd)
  - docker (dockershim)
  - mirantis Container Runtime
- cri-dockerd
  > Container_Runtime <- Container  Runtime Interface <- kubelet <- - API_Service

# Deployment File

> https://kubernetes.io/docs/concepts/overview/working-with-objects/


## Identity Access Management
Who`service account`? Do what `action`? On What `resource`?
Identity
- Google Account
- Service Account
- Group
- Cloud ID

Police -> roles -> premission [service. resource. verb]


# K8 Networking
> Container Network Interface (CNI) default Calico-node

> The container runtime offloads the IP assignment to CNI

> IP-per-Pod is each Pod receiving a unique IP address

> container within same pod connect through localhost

> Services, complex encapsulations of network routing rule definitions stored in iptables on cluster nodes and implemented by kube-proxy agents. 

install tools
kubeadm
kubespray/kargo (base off Ansible)
kops

Examples of controllers are Deployments, ReplicaSets, DaemonSets, Jobs, etc.
DaemonSets enforce single pod per node on all nodes (for monitor logs, storage, network)
ReplicaSet is outdated

VM Driver
- podman
- virtualbox

kubectl config view
Default Paths
/var/lib/minikube/certs/
~/.kube/config

Normal Users manage by independent services like User/Client Certificates
Service Accounts communicate with the API server to perform various operations.

### authentication modules:
- X509 Client Certificates
- Static Token File
- Bootstrap Tokens
- Service Account Tokens
- OpenID Connect Tokens
- Webhook Token Authentication
- Authenticating Proxy


sudo cp /etc/kubernetes/manifests/kube-apiserver.yamml /kube-apiserver-backup
just add extra param
takes 20-40 seconds for api-server restart


The user/client now connects to a Service via its ClusterIP, which forwards traffic to one of the Pods attached to it. A Service provides load balancing by default while selecting the Pods for traffic forwarding.

Service.targetPort = Pod.spec.containerPort

Service's endpoints is auto created by k8, Ex:(10.1.1.1:5000, 10.1.1.2:5000)
can I manually test Service's endpoints? 10.1.1.1:5000

Traffic police
Local: exposed to only same node

my-svc.my-namespace.svc.cluster.local

to test ClustIP
minikube ssh | gcloud compute ssh <NODE_NAME> --zone <ZONE>
//endpoint is POD's IP
curl endpoint:port
// Each Service has kubeproxy virtual IP
curl service_ip

## Volume Type
- emptyDir // deleted after POD dead
- hostPath // exists after POD dead. on node?
- cephfs
- nfs
- iscsi
- secret
  - secret data `must be base64`
  - stringData `is string`
- configMap
- persistentVolumeClaim(PVC)


### Cloud volumns
- gcePersistentDisk // GCP
- awsElasticBlockStore
- azureDisk
- azureFile



annotations is NOT used by selector

## Job
- parallelism - `to set the number of pods allowed to run in parallel;`
- completions - `to set the number of expected completions;`
- activeDeadlineSeconds - `to set the duration of the Job;`
- backoffLimit - `to set the number of retries before Job is marked as failed;`
- ttlSecondsAfterFinished - `to delay the clean up of the finished Jobs.`

## CronJobs
- startingDeadlineSeconds - `to set the deadline to start a Job if scheduled time was missed;`
- concurrencyPolicy - `to allow or forbid concurrent Jobs or to replace old Jobs with new ones. `

### Service Mesh Addons:
- Consul
- Envoy
- Istio
- Kuma
- Linkerd
- Maesh
- Tanzu Service Mesh

Advance Deployement
Canary - 2 different version at same time
Blue/Green - Completed switch over
> Create another service with selector able select both version PODs

**Certificate**
- LFS158x
- Kubernetes Fundamentals (LFS258)
- Certified Kubernetes Administrator (CKA)
- Kubernetes for Developers (LFD259)
- Certified Kubernetes Application Developer (CKAD)


# Commons Erros
- Error Validating data
- SchedulingDisabled
- ImagePullBackoff
- CashLoopBackoff
- CreateContainerError
- Probe Failling
- RunContainerError
- Exceed CPU Limits
- FailedScheduling
- Failed Mount
- Kubelet crash

# Helm
> Helm is package manager for k8, also templating Engines
helm install --values=xxx.yaml chart_name

> IDK is it worth it to learn Helm, maybe deploy through terrform? I don't know any killer apps from Helm.
Helm < 2.0
Client / Sever (Tiller)
>= 3.0 No more Tiller


`helm template Release1 helm-charts`

/helm-charts
  /charts
  /templates (what k8 objects creates)
  .values.yaml (k8 values)
  .Chart.yaml (chart meta info)

{{ include "helm-cahrts.labels" . | nindent 4 }}
{{ .Values.service.name | qoute }}

// - remove line space
test:
  {{- .Release.Name }}

{{- toYaml .Values.xxx | nindent 8 }}

