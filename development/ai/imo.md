# IMO
> Collection of my thoughts & guess. No evident needs, just a crazy person's notes here.
> 
> Break my opinions into:
- strong opinions
- weak opinions `require many conditions to be true`
- random ideas
- cray notes

## Strong Opinions
> I don't beveled human brain is the only way to achieve intelligent. Many ppl still consider llm just auto complete, just evident by llm failed simple human task. But that assumes intelligent must follow human path. 

> IMO: most important in AI is right question `aka desire` & measurement of progress `aka value`.

> My opinion of neural network is a lossy compression model.

> Every human ability requires a decoder from context token? So hands movement needs hand decoder, speak needs speech decoder, running need leg decoder? 

> NN connection is too static. Human neurons can create new connection. Need dynamic connection ability in NN.

- I think we need more localized, more parallel algorithms. I think back propagation is too global. My guess is unfired neuron stack up voltage cause correction.

- Most likely llm's problem is there is a single intermediate state that holds though, planning, intentions, understanding, 

- Seems like building AGI requires many "components/skills", we need AI able to count, 2D understanding, 3D understanding, read, listen, speak, write ....etc. Just achieved one doesn't mean others are so easily done. We need to look deep into ourself what are fundamental skills we have.

- Healthy people are more flexible movement; Won't trick by trick questions; A key measurement for AI should be same thing, how hard to trick AI. 

- AI can think of compression algorithm. In fact it may be too good. A lot knowledge able to compress into 20GB model. Maybe the problem is we COMPRESS too much! That's why bigger model shows better intelligence.

> Why AI need so much computation? Interesting to compare traditional Lossy Compression Algorithms which uses very few computation.
>> Compression Algorithms start from data to away from data, AI start from randomness to target. Perception Coding

> We are environment feedback; AI is same; AI can easily traversal through digital world; But in physical world, AI will just be like us, only experience subset of reality. AI most likely will experience more than any single human, but AI still limited by its experience ability.
> > Most important thing is feedback system.
>
> People lives in a house; Sames for AI, AI lives on hardware; Some AI can squeeze in small PC, of course can't do as much.

## Weak Opinions
> Another cue is human train to response faster, rational thinking is slower. Seem like AI just have "instinct" right now.

> Language Model is statical model of large text db. AI usually very agreeable/static basie.

> AI sucks at Abbreviation. 

## crazy notes
> Best way measure understanding(both human & AI) is operation/alteration after compression.
