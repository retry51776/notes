# Paper
"Explaining and Harnessing Adversarial Examples" by Ian Goodfellow, et al. (2014): This paper introduces the concept of "adversarial examples," which are inputs to machine learning models that have been specifically designed to cause the model to make mistakes. The paper has had a significant impact on the field of adversarial machine learning, and it has spurred the development of many techniques for defending against adversarial examples.

"Human-level performance in multi-task reinforcement learning" by Volodymyr Mnih, et al. (2015): This paper presents the "DQN" algorithm, which was able to achieve human-level performance on a suite of Atari 2600 games using reinforcement learning. This was a significant achievement in the field of reinforcement learning, and it laid the foundation for many subsequent advances in the area.

"Attention Is All You Need" by Vaswani, et al. (2017): This paper introduces the "Transformer" model, which is a type of neural network that is particularly well-suited for natural language processing tasks. The Transformer model has had a significant impact on the field of NLP, and it has been used in a variety of applications, including machine translation and language modeling.

Filter query step:
The idea is embedding layer encoded w position info. Then train attention matrix(n^2) to capture relationship weights; Then attention matrix times embedding layer to get filtered input.

"DeepMind and Blizzard Entertainment are working to build the definitive version of Starcraft II for AI research" by David Silver, et al. (2017): This paper describes the collaboration between DeepMind and Blizzard Entertainment to create a version of the Starcraft II video game that is optimized for use in AI research. The game has since become a popular benchmark for AI algorithms, and it has been used in a number of research papers and competitions.

"GPT-3: Language Models are Few-Shot Learners" by Alec Radford, et al. (2021): This paper introduces the "GPT-3" language model, which is one of the largest and most powerful language models to date. GPT-3 has been able to achieve state-of-the-art results on a variety of NLP tasks, and it has been used in a number of interesting applications, including machine translation, text summarization, and question answering.